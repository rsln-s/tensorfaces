{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import menpo.io as mio\n",
    "from menpo.visualize import print_progress\n",
    "from menpo.landmark import labeller, face_ibug_68_to_face_ibug_68_trimesh\n",
    "\n",
    "path_to_images = '/home/rshaydu/tensorfaces/helen/trainset/'\n",
    "training_images = []\n",
    "for img in print_progress(mio.import_images(path_to_images, verbose=True)):\n",
    "    # convert to greyscale\n",
    "    if img.n_channels == 3:\n",
    "        img = img.as_greyscale()\n",
    "    # crop to landmarks bounding box with an extra 20% padding\n",
    "    img = img.crop_to_landmarks_proportion(0.2)\n",
    "    # rescale image if its diagonal is bigger than 400 pixels\n",
    "    d = img.diagonal()\n",
    "    if d > 400:\n",
    "        img = img.rescale(400.0 / d)\n",
    "    # define a TriMesh which will be useful for Piecewise Affine Warp of HolisticAAM\n",
    "    labeller(img, 'PTS', face_ibug_68_to_face_ibug_68_trimesh)\n",
    "    # append to list\n",
    "    training_images.append(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from menpowidgets import visualize_images\n",
    "visualize_images(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from menpofit.aam import PatchAAM\n",
    "# from menpo.feature import fast_dsift\n",
    "\n",
    "# patch_aam = PatchAAM(training_images, group='PTS', patch_shape=[(15, 15), (23, 23)],\n",
    "#                      diagonal=150, scales=(0.5, 1.0), holistic_features=fast_dsift,\n",
    "#                      max_shape_components=20, max_appearance_components=150,\n",
    "#                      verbose=True)\n",
    "from menpofit.aam import HolisticAAM\n",
    "from menpo.feature import fast_dsift\n",
    "\n",
    "aam = HolisticAAM(training_images, group='face_ibug_68_trimesh', diagonal=150,\n",
    "                  scales=(0.5, 1.0), holistic_features=fast_dsift, verbose=True,\n",
    "                  max_shape_components=20, max_appearance_components=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aam.view_appearance_models_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aam.view_aam_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "\n",
    "fitter = LucasKanadeAAMFitter(aam, lk_algorithm_cls=WibergInverseCompositional,\n",
    "                              n_shape=[5, 20], n_appearance=[30, 150])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import menpo.io as mio\n",
    "\n",
    "path_to_lfpw = Path('/home/rshaydu/tensorfaces/helen/testset/')\n",
    "\n",
    "image = mio.import_image(path_to_lfpw / '296814969_3.jpg')\n",
    "image = image.as_greyscale()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "\n",
    "# Load detector\n",
    "detect = load_opencv_frontal_face_detector()\n",
    "\n",
    "# Detect\n",
    "bboxes = detect(image)\n",
    "print(\"{} detected faces.\".format(len(bboxes)))\n",
    "\n",
    "# View\n",
    "if len(bboxes) > 0:\n",
    "    image.view_landmarks(group='opencv_0', line_colour='red',\n",
    "                         render_markers=False, line_width=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial bbox\n",
    "initial_bbox = bboxes[0]\n",
    "\n",
    "# fit image\n",
    "result = fitter.fit_from_bb(image, initial_bbox, max_iters=[15, 5],\n",
    "                            gt_shape=image.landmarks['PTS'])\n",
    "\n",
    "# print result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.view(render_initial_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = fitter.warped_images(result.image, [result.final_shape])\n",
    "warped[0].view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from menpodetect import load_ffld2_frontal_face_detector\n",
    "\n",
    "# # Load detector\n",
    "# detect = load_ffld2_frontal_face_detector()\n",
    "\n",
    "# # Detect\n",
    "# bboxes = detect(image)\n",
    "# print(\"{} detected faces.\".format(len(bboxes)))\n",
    "\n",
    "# # View\n",
    "# if len(bboxes) > 0:\n",
    "#     image.view_landmarks(group='llfd2_0', line_colour='red',\n",
    "#                          render_markers=False, line_width=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "\n",
    "\n",
    "# Load and convert to grayscale\n",
    "image = mio.import_image('/home/rshaydu/tensorfaces/FaceBase_png/amir-vp0-il1-ex2.png')\n",
    "image = image.as_greyscale()\n",
    "\n",
    "# Load detector\n",
    "detect = load_dlib_frontal_face_detector()\n",
    "\n",
    "# # Detect face\n",
    "bboxes = detect(image)\n",
    "if len(bboxes) > 0:\n",
    "    image.view_landmarks(group='dlib_0', line_colour='red',\n",
    "                         render_markers=False, line_width=4);\n",
    "else:\n",
    "    print(\"Error: no faces detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import menpo\n",
    "\n",
    "# initial bbox\n",
    "# build box by hand\n",
    "adjacency_matrix = np.array([[0,1,0,0],\n",
    "                             [0,0,1,0],\n",
    "                             [0,0,0,1],\n",
    "                             [1,0,0,0]])\n",
    "# points = np.array([[150,100],[500,100],[500,300],[150,300]]) # fine for looking right\n",
    "points = np.array([[120,75],[450,75],[450,275],[120,275]])\n",
    "\n",
    "initial_bbox = menpo.shape.PointDirectedGraph(points, adjacency_matrix)\n",
    "\n",
    "# fit image\n",
    "result = fitter.fit_from_bb(image, bboxes[0], max_iters=50)\n",
    "\n",
    "# print result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.view(render_initial_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.view_iterations()\n",
    "result.image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "# cropped = image.crop_to_pointcloud(result.final_shape)\n",
    "# cropped.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = fitter.warped_images(result.image, [result.final_shape, fitter.reference_shape])\n",
    "warped[0].view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menpo",
   "language": "python",
   "name": "menpo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
