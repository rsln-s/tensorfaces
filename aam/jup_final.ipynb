{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import menpo.io as mio\n",
    "from menpo.visualize import print_progress\n",
    "from menpo.landmark import labeller, face_ibug_68_to_face_ibug_68_trimesh\n",
    "from menpofit.aam import HolisticAAM\n",
    "from menpo.feature import fast_dsift\n",
    "from menpofit.aam import LucasKanadeAAMFitter, WibergInverseCompositional\n",
    "import numpy as np\n",
    "import menpo\n",
    "\n",
    "path_to_images = '/home/rshaydu/tensorfaces/helen/trainset/'\n",
    "training_images = []\n",
    "for img in print_progress(mio.import_images(path_to_images, verbose=True)):\n",
    "    # convert to greyscale\n",
    "    if img.n_channels == 3:\n",
    "        img = img.as_greyscale()\n",
    "    # crop to landmarks bounding box with an extra 20% padding\n",
    "    img = img.crop_to_landmarks_proportion(0.2)\n",
    "    # rescale image if its diagonal is bigger than 400 pixels\n",
    "    d = img.diagonal()\n",
    "    if d > 400:\n",
    "        img = img.rescale(400.0 / d)\n",
    "    # define a TriMesh which will be useful for Piecewise Affine Warp of HolisticAAM\n",
    "    labeller(img, 'PTS', face_ibug_68_to_face_ibug_68_trimesh)\n",
    "    # append to list\n",
    "    training_images.append(img)\n",
    "\n",
    "aam = HolisticAAM(training_images, group='face_ibug_68_trimesh', diagonal=150,\n",
    "                  scales=(0.5, 1.0), holistic_features=fast_dsift, verbose=True,\n",
    "                  max_shape_components=20, max_appearance_components=150)\n",
    "\n",
    "\n",
    "fitter = LucasKanadeAAMFitter(aam, lk_algorithm_cls=WibergInverseCompositional,\n",
    "                              n_shape=[5, 20], n_appearance=[30, 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from menpodetect import load_dlib_frontal_face_detector\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load and convert to grayscale\n",
    "image_folder = '/home/rshaydu/tensorfaces/FaceBase_png/'\n",
    "img_files = list(filter(lambda x: \".png\" in x, os.listdir(image_folder)))\n",
    "\n",
    "# somewhere here a for loop starts\n",
    "\n",
    "for img_file in img_files:\n",
    "    img_path = image_folder+img_file\n",
    "\n",
    "    print(\"Landmarking \", img_path)\n",
    "\n",
    "    image = mio.import_image(img_path)\n",
    "    image = image.as_greyscale()\n",
    "\n",
    "    # Load detector\n",
    "    detect = load_dlib_frontal_face_detector()\n",
    "\n",
    "    # # Detect face\n",
    "    bboxes = detect(image)\n",
    "    initial_box = None\n",
    "    if len(bboxes) > 0:\n",
    "        initial_bbox = bboxes[0]\n",
    "        print(\"dlib_frontal_face_detector found an initial box\")\n",
    "    else:\n",
    "    # initial bbox\n",
    "    # build box by hand\n",
    "        adjacency_matrix = np.array([[0,1,0,0],\n",
    "                                     [0,0,1,0],\n",
    "                                     [0,0,0,1],\n",
    "                                     [1,0,0,0]])\n",
    "\n",
    "        points = None\n",
    "        if 'vp0' in img_path or 'vp1' in img_path:\n",
    "            points = np.array([[150,100],[500,100],[500,300],[150,300]]) # fine for looking right\n",
    "        elif 'vp3' in img_path or 'vp4' in img_path:\n",
    "            points = np.array([[120,50],[500,50],[500,250],[120,250]])\n",
    "        elif 'vp0' in img_path:\n",
    "            points = np.array([[120,75],[500,75],[500,275],[120,275]])\n",
    "\n",
    "        if points == None:\n",
    "            print(\"Error: incorrect finename\", img_path)\n",
    "            sys.exit(0)\n",
    "\n",
    "        initial_bbox = menpo.shape.PointDirectedGraph(points, adjacency_matrix)\n",
    "        print(\"Using a hardcoded initial box\")\n",
    "\n",
    "    # fit image\n",
    "    result = fitter.fit_from_bb(image, initial_bbox, max_iters=200)\n",
    "\n",
    "    # print result\n",
    "#     result.view(render_initial_shape=True)\n",
    "    # PROBLEM: only renders widgets when the cell has finished computing\n",
    "#     print(\"Looks ok?\")\n",
    "#     while True:\n",
    "#         user_inp = input()\n",
    "#         if user_inp == 'y':\n",
    "    warped = fitter.warped_images(result.image, [result.final_shape, fitter.reference_shape])\n",
    "            # warped[0].view()\n",
    "    mio.export_image(warped[0],\"/home/rshaydu/tensorfaces/FaceBase_warped/\"+img_file)\n",
    "#             break\n",
    "#         elif user_inp == 'n':\n",
    "    menpo.io.export_landmark_file(result.final_shape, \"/home/rshaydu/tensorfaces/FaceBase_warped/\"+img_file.split('.')[0]+\".pts\")\n",
    "#             break\n",
    "#         clear_output()\n",
    "#         print(\"Incorrect input: \", user_inp, \" Please, try again.\")\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menpo",
   "language": "python",
   "name": "menpo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
